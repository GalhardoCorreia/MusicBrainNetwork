{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music and the Brain \n",
    "## 0. Setup and load data from 0.[decoding]feature-extraction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import nilearn\n",
    "import joblib as jl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn.image import concat_imgs, mean_img\n",
    "from nilearn.plotting import plot_anat, plot_img, plot_stat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data directory\n",
    "src_dir = '../data/derivatives/nilearn'\n",
    "\n",
    "# Set the participant and session IDs\n",
    "part_id = ['sub-01', 'sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10']\n",
    "ses_id = 'ses-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-01_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-01_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-01_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-01_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-02_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-02_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-02_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-02_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-03_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-03_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-03_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-03_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-04_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-04_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-04_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-04_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-05_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-05_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-05_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-05_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-06_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-06_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-06_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-06_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-07_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-07_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-07_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-07_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-08_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-08_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-08_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-08_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-09_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-09_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-09_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-09_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-10_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-10_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-10_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', 'sub-10_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz']\n",
      "..\\data\\sub-10\\ses-01\\func\n"
     ]
    }
   ],
   "source": [
    "func_dir = \"..\\data\"\n",
    "\n",
    "func_runs_all = []\n",
    "\n",
    "\n",
    "for id in part_id:\n",
    "    #funcdir_path.append(os.path.join(func_dir, id, ses_id, 'func'))  # Append to list\n",
    "    funcdir_path= os.path.join(func_dir, id, ses_id, 'func')\n",
    "    func_runs = os.listdir(funcdir_path)\n",
    "    func_runs = [f for f in func_runs if f.endswith('bold.nii.gz')]\n",
    "    func_runs_all.extend(func_runs)\n",
    "    \n",
    "\n",
    "print(func_runs_all)\n",
    "print(funcdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_func_runs_all = []\n",
    "\n",
    "for id in part_id:\n",
    "    #funcdir_path.append(os.path.join(func_dir, id, ses_id, 'func'))  # Append to list\n",
    "    funcdir_path= os.path.join(func_dir, id, ses_id, 'func')\n",
    "    func_runs = os.listdir(funcdir_path)\n",
    "    func_runs = [f for f in func_runs if f.endswith('bold.nii.gz')]\n",
    "\n",
    "    c_func_runs = [os.path.join(funcdir_path, f) for f in func_runs]\n",
    "    c_func_runs_all.extend(c_func_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\data\\\\sub-01\\\\ses-01\\\\func\\\\sub-01_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-01\\\\ses-01\\\\func\\\\sub-01_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-01\\\\ses-01\\\\func\\\\sub-01_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-01\\\\ses-01\\\\func\\\\sub-01_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-02\\\\ses-01\\\\func\\\\sub-02_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-02\\\\ses-01\\\\func\\\\sub-02_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-02\\\\ses-01\\\\func\\\\sub-02_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-02\\\\ses-01\\\\func\\\\sub-02_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-03\\\\ses-01\\\\func\\\\sub-03_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-03\\\\ses-01\\\\func\\\\sub-03_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-03\\\\ses-01\\\\func\\\\sub-03_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-03\\\\ses-01\\\\func\\\\sub-03_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-04\\\\ses-01\\\\func\\\\sub-04_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-04\\\\ses-01\\\\func\\\\sub-04_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-04\\\\ses-01\\\\func\\\\sub-04_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-04\\\\ses-01\\\\func\\\\sub-04_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-05\\\\ses-01\\\\func\\\\sub-05_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-05\\\\ses-01\\\\func\\\\sub-05_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-05\\\\ses-01\\\\func\\\\sub-05_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-05\\\\ses-01\\\\func\\\\sub-05_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-06\\\\ses-01\\\\func\\\\sub-06_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-06\\\\ses-01\\\\func\\\\sub-06_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-06\\\\ses-01\\\\func\\\\sub-06_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-06\\\\ses-01\\\\func\\\\sub-06_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-07\\\\ses-01\\\\func\\\\sub-07_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-07\\\\ses-01\\\\func\\\\sub-07_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-07\\\\ses-01\\\\func\\\\sub-07_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-07\\\\ses-01\\\\func\\\\sub-07_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-08\\\\ses-01\\\\func\\\\sub-08_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-08\\\\ses-01\\\\func\\\\sub-08_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-08\\\\ses-01\\\\func\\\\sub-08_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-08\\\\ses-01\\\\func\\\\sub-08_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-09\\\\ses-01\\\\func\\\\sub-09_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-09\\\\ses-01\\\\func\\\\sub-09_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-09\\\\ses-01\\\\func\\\\sub-09_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-09\\\\ses-01\\\\func\\\\sub-09_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-10\\\\ses-01\\\\func\\\\sub-10_ses-01_task-02a_run-1_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-10\\\\ses-01\\\\func\\\\sub-10_ses-01_task-02a_run-2_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-10\\\\ses-01\\\\func\\\\sub-10_ses-01_task-02a_run-3_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz', '..\\\\data\\\\sub-10\\\\ses-01\\\\func\\\\sub-10_ses-01_task-02a_run-4_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "from nilearn.masking import compute_epi_mask, compute_multi_epi_mask\n",
    "\n",
    "print(c_func_runs_all)\n",
    "mask_img = compute_multi_epi_mask(c_func_runs_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nilearn.plotting.displays._slicers.OrthoSlicer at 0x20ad62bd070>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 660x350 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = []\n",
    "\n",
    "for id in part_id:\n",
    "    data_dir.append(os.path.join(src_dir, id, ses_id))  # Append to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/derivatives/nilearn\\\\sub-01\\\\ses-01', '../data/derivatives/nilearn\\\\sub-02\\\\ses-01', '../data/derivatives/nilearn\\\\sub-03\\\\ses-01', '../data/derivatives/nilearn\\\\sub-04\\\\ses-01', '../data/derivatives/nilearn\\\\sub-05\\\\ses-01', '../data/derivatives/nilearn\\\\sub-06\\\\ses-01', '../data/derivatives/nilearn\\\\sub-07\\\\ses-01', '../data/derivatives/nilearn\\\\sub-08\\\\ses-01', '../data/derivatives/nilearn\\\\sub-09\\\\ses-01', '../data/derivatives/nilearn\\\\sub-10\\\\ses-01']\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/derivatives/nilearn\\sub-02\\ses-01\\sub-02_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-03\\ses-01\\sub-03_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-04\\ses-01\\sub-04_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-05\\ses-01\\sub-05_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-06\\ses-01\\sub-06_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-07\\ses-01\\sub-07_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-08\\ses-01\\sub-08_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-09\\ses-01\\sub-09_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n",
      "../data/derivatives/nilearn\\sub-10\\ses-01\\sub-10_ses-01_task-02a-MVPA-12sBOLD_clean.nii.gz\n"
     ]
    }
   ],
   "source": [
    "X_total = []\n",
    "target_total = []\n",
    "\n",
    "for i in range(1, len(data_dir)):\n",
    "\n",
    "    # Load feature set.\n",
    "    X=image.load_img(os.path.join(data_dir[i], f'{part_id[i]}_{ses_id}_task-02a-MVPA-12sBOLD_clean.nii.gz'))\n",
    "    print(os.path.join(data_dir[i], f'{part_id[i]}_{ses_id}_task-02a-MVPA-12sBOLD_clean.nii.gz'))\n",
    "\n",
    "    X_total.append(X)\n",
    "\n",
    "    \n",
    "    # Load csv file with targets.\n",
    "    target_set = pd.read_csv(os.path.join(data_dir[i], f'{part_id[i]}_{ses_id}_task-02a-MVPA-12sBOLD_targets_clean.csv'))\n",
    "    target_total.append(target_set['target'])\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMasker\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nilearn.decoding import Decoder\n",
    "# “background”: Use this option if your images present a clear homogeneous background.\n",
    "# “whole-brain-template”: This will extract the whole-brain part of your data by resampling \n",
    "# the MNI152 brain mask for your data’s field of view.\n",
    "\n",
    "\n",
    "logo = LeaveOneGroupOut()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<nibabel.nifti1.Nifti1Image object at 0x0000020ADB5FE3A0>, <nibabel.nifti1.Nifti1Image object at 0x0000020D526E8F40>, <nibabel.nifti1.Nifti1Image object at 0x0000020D526E8D30>, <nibabel.nifti1.Nifti1Image object at 0x0000020D526E8C40>, <nibabel.nifti1.Nifti1Image object at 0x0000020D527100A0>, <nibabel.nifti1.Nifti1Image object at 0x0000020D52710EE0>, <nibabel.nifti1.Nifti1Image object at 0x0000020ADB6F2EB0>, <nibabel.nifti1.Nifti1Image object at 0x0000020ADB6F2B80>, <nibabel.nifti1.Nifti1Image object at 0x0000020ADB6F20A0>]\n",
      "(97, 115, 97, 684)\n"
     ]
    }
   ],
   "source": [
    "print(X_total)\n",
    "X_total = image.concat_imgs(X_total)\n",
    "print(X_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0      Noise_ToDiscard\n",
      "1         Peacefulness\n",
      "2         Peacefulness\n",
      "3           Tenderness\n",
      "4           Tenderness\n",
      "            ...       \n",
      "71       Transcendence\n",
      "72    JoyfulActivation\n",
      "73    JoyfulActivation\n",
      "74              Wonder\n",
      "75              Wonder\n",
      "Name: target, Length: 76, dtype: object, 0     Noise_ToDiscard\n",
      "1       Transcendence\n",
      "2       Transcendence\n",
      "3          Tenderness\n",
      "4          Tenderness\n",
      "           ...       \n",
      "71       Peacefulness\n",
      "72              Power\n",
      "73              Power\n",
      "74          Nostalgia\n",
      "75          Nostalgia\n",
      "Name: target, Length: 76, dtype: object, 0     Noise_ToDiscard\n",
      "1              Wonder\n",
      "2              Wonder\n",
      "3             Tension\n",
      "4             Tension\n",
      "           ...       \n",
      "71          Nostalgia\n",
      "72              Power\n",
      "73              Power\n",
      "74            Sadness\n",
      "75            Sadness\n",
      "Name: target, Length: 76, dtype: object, 0     Noise_ToDiscard\n",
      "1        Peacefulness\n",
      "2        Peacefulness\n",
      "3             Tension\n",
      "4             Tension\n",
      "           ...       \n",
      "71          Nostalgia\n",
      "72       Peacefulness\n",
      "73       Peacefulness\n",
      "74             Wonder\n",
      "75             Wonder\n",
      "Name: target, Length: 76, dtype: object, 0      Noise_ToDiscard\n",
      "1        Transcendence\n",
      "2        Transcendence\n",
      "3              Tension\n",
      "4              Tension\n",
      "            ...       \n",
      "71             Tension\n",
      "72           Nostalgia\n",
      "73           Nostalgia\n",
      "74    JoyfulActivation\n",
      "75    JoyfulActivation\n",
      "Name: target, Length: 76, dtype: object, 0      Noise_ToDiscard\n",
      "1               Wonder\n",
      "2               Wonder\n",
      "3              Tension\n",
      "4              Tension\n",
      "            ...       \n",
      "71    JoyfulActivation\n",
      "72               Power\n",
      "73               Power\n",
      "74             Sadness\n",
      "75             Sadness\n",
      "Name: target, Length: 76, dtype: object, 0      Noise_ToDiscard\n",
      "1               Wonder\n",
      "2               Wonder\n",
      "3            Nostalgia\n",
      "4            Nostalgia\n",
      "            ...       \n",
      "71    JoyfulActivation\n",
      "72       Transcendence\n",
      "73       Transcendence\n",
      "74        Peacefulness\n",
      "75        Peacefulness\n",
      "Name: target, Length: 76, dtype: object, 0     Noise_ToDiscard\n",
      "1       Transcendence\n",
      "2       Transcendence\n",
      "3              Wonder\n",
      "4              Wonder\n",
      "           ...       \n",
      "71      Transcendence\n",
      "72            Tension\n",
      "73            Tension\n",
      "74       Peacefulness\n",
      "75       Peacefulness\n",
      "Name: target, Length: 76, dtype: object, 0      Noise_ToDiscard\n",
      "1        Transcendence\n",
      "2        Transcendence\n",
      "3     JoyfulActivation\n",
      "4     JoyfulActivation\n",
      "            ...       \n",
      "71             Tension\n",
      "72       Transcendence\n",
      "73       Transcendence\n",
      "74          Tenderness\n",
      "75          Tenderness\n",
      "Name: target, Length: 76, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "print(target_total)\n",
    "target_total = pd.concat(target_total).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Noise_ToDiscard', 'Peacefulness', 'Peacefulness', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Nostalgia', 'Nostalgia', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Noise_ToDiscard', 'JoyfulActivation', 'JoyfulActivation', 'Transcendence', 'Transcendence', 'Nostalgia', 'Nostalgia', 'Peacefulness', 'Peacefulness', 'Power', 'Power', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Tenderness', 'Tenderness', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Sadness', 'Sadness', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Peacefulness', 'Peacefulness', 'Tenderness', 'Tenderness', 'JoyfulActivation', 'JoyfulActivation', 'Tension', 'Tension', 'Power', 'Power', 'Noise_ToDiscard', 'Peacefulness', 'Peacefulness', 'Tenderness', 'Tenderness', 'Nostalgia', 'Nostalgia', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Power', 'Power', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Wonder', 'Wonder', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Tenderness', 'Tenderness', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Power', 'Power', 'Tension', 'Tension', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Nostalgia', 'Nostalgia', 'Sadness', 'Sadness', 'Tension', 'Tension', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Wonder', 'Wonder', 'Transcendence', 'Transcendence', 'Tenderness', 'Tenderness', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Tenderness', 'Tenderness', 'Tension', 'Tension', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Sadness', 'Sadness', 'Peacefulness', 'Peacefulness', 'Power', 'Power', 'Wonder', 'Wonder', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Tenderness', 'Tenderness', 'JoyfulActivation', 'JoyfulActivation', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'Power', 'Power', 'Nostalgia', 'Nostalgia', 'Noise_ToDiscard', 'Wonder', 'Wonder', 'Tension', 'Tension', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Power', 'Power', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Power', 'Power', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Tenderness', 'Tenderness', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Sadness', 'Sadness', 'Peacefulness', 'Peacefulness', 'Wonder', 'Wonder', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Tenderness', 'Tenderness', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Power', 'Power', 'Noise_ToDiscard', 'JoyfulActivation', 'JoyfulActivation', 'Tenderness', 'Tenderness', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'Transcendence', 'Transcendence', 'Nostalgia', 'Nostalgia', 'Power', 'Power', 'Sadness', 'Sadness', 'Noise_ToDiscard', 'Peacefulness', 'Peacefulness', 'Tension', 'Tension', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Power', 'Power', 'Sadness', 'Sadness', 'Noise_ToDiscard', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'JoyfulActivation', 'JoyfulActivation', 'Tenderness', 'Tenderness', 'Power', 'Power', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'Noise_ToDiscard', 'Power', 'Power', 'Wonder', 'Wonder', 'Sadness', 'Sadness', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Nostalgia', 'Nostalgia', 'JoyfulActivation', 'JoyfulActivation', 'Tenderness', 'Tenderness', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Power', 'Power', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Peacefulness', 'Peacefulness', 'Wonder', 'Wonder', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Peacefulness', 'Peacefulness', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Noise_ToDiscard', 'Peacefulness', 'Peacefulness', 'Power', 'Power', 'Tension', 'Tension', 'Nostalgia', 'Nostalgia', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'Wonder', 'Wonder', 'JoyfulActivation', 'JoyfulActivation', 'Sadness', 'Sadness', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Power', 'Power', 'Tension', 'Tension', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Tenderness', 'Tenderness', 'Wonder', 'Wonder', 'Sadness', 'Sadness', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Power', 'Power', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'Peacefulness', 'Peacefulness', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Nostalgia', 'Nostalgia', 'JoyfulActivation', 'JoyfulActivation', 'Noise_ToDiscard', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Transcendence', 'Transcendence', 'Sadness', 'Sadness', 'Nostalgia', 'Nostalgia', 'Tenderness', 'Tenderness', 'Noise_ToDiscard', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Noise_ToDiscard', 'Peacefulness', 'Peacefulness', 'Transcendence', 'Transcendence', 'Power', 'Power', 'JoyfulActivation', 'JoyfulActivation', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Noise_ToDiscard', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'Tenderness', 'Tenderness', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Sadness', 'Sadness', 'Noise_ToDiscard', 'Wonder', 'Wonder', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Peacefulness', 'Peacefulness', 'Power', 'Power', 'Tenderness', 'Tenderness', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Noise_ToDiscard', 'Nostalgia', 'Nostalgia', 'JoyfulActivation', 'JoyfulActivation', 'Sadness', 'Sadness', 'Power', 'Power', 'Wonder', 'Wonder', 'Peacefulness', 'Peacefulness', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Noise_ToDiscard', 'Tenderness', 'Tenderness', 'Nostalgia', 'Nostalgia', 'JoyfulActivation', 'JoyfulActivation', 'Transcendence', 'Transcendence', 'Power', 'Power', 'Peacefulness', 'Peacefulness', 'Wonder', 'Wonder', 'Sadness', 'Sadness', 'Tension', 'Tension', 'Noise_ToDiscard', 'Tenderness', 'Tenderness', 'Power', 'Power', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Sadness', 'Sadness', 'Tension', 'Tension', 'JoyfulActivation', 'JoyfulActivation', 'Transcendence', 'Transcendence', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Wonder', 'Wonder', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Power', 'Power', 'Nostalgia', 'Nostalgia', 'Tenderness', 'Tenderness', 'JoyfulActivation', 'JoyfulActivation', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Peacefulness', 'Peacefulness', 'JoyfulActivation', 'JoyfulActivation', 'Sadness', 'Sadness', 'Wonder', 'Wonder', 'Tenderness', 'Tenderness', 'Nostalgia', 'Nostalgia', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Power', 'Power', 'Noise_ToDiscard', 'Sadness', 'Sadness', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'Power', 'Power', 'JoyfulActivation', 'JoyfulActivation', 'Noise_ToDiscard', 'Sadness', 'Sadness', 'JoyfulActivation', 'JoyfulActivation', 'Power', 'Power', 'Nostalgia', 'Nostalgia', 'Wonder', 'Wonder', 'Tenderness', 'Tenderness', 'Transcendence', 'Transcendence', 'Tension', 'Tension', 'Peacefulness', 'Peacefulness', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'JoyfulActivation', 'JoyfulActivation', 'Peacefulness', 'Peacefulness', 'Nostalgia', 'Nostalgia', 'Tension', 'Tension', 'Sadness', 'Sadness', 'Tenderness', 'Tenderness', 'Wonder', 'Wonder', 'Power', 'Power', 'Noise_ToDiscard', 'Transcendence', 'Transcendence', 'Peacefulness', 'Peacefulness', 'Wonder', 'Wonder', 'Sadness', 'Sadness', 'Power', 'Power', 'Tenderness', 'Tenderness', 'JoyfulActivation', 'JoyfulActivation', 'Tension', 'Tension', 'Nostalgia', 'Nostalgia', 'Noise_ToDiscard', 'Tension', 'Tension', 'Wonder', 'Wonder', 'Tenderness', 'Tenderness', 'Nostalgia', 'Nostalgia', 'Sadness', 'Sadness', 'Power', 'Power', 'Peacefulness', 'Peacefulness', 'JoyfulActivation', 'JoyfulActivation', 'Transcendence', 'Transcendence', 'Noise_ToDiscard', 'Sadness', 'Sadness', 'Power', 'Power', 'Peacefulness', 'Peacefulness', 'Wonder', 'Wonder', 'JoyfulActivation', 'JoyfulActivation', 'Nostalgia', 'Nostalgia', 'Tension', 'Tension', 'Transcendence', 'Transcendence', 'Tenderness', 'Tenderness']\n",
      "[1 3 3 6 6 8 8 0 0 4 4 2 2 7 7 5 5 9 9 1 0 0 8 8 2 2 3 3 4 4 5 5 9 9 7 7 6\n",
      " 6 1 8 8 5 5 2 2 9 9 3 3 6 6 0 0 7 7 4 4 1 3 3 6 6 2 2 7 7 5 5 4 4 8 8 0 0\n",
      " 9 9 1 8 8 6 6 5 5 9 9 4 4 7 7 0 0 2 2 3 3 1 2 2 5 5 7 7 0 0 4 4 9 9 8 8 6\n",
      " 6 3 3 1 6 6 7 7 2 2 8 8 0 0 5 5 3 3 4 4 9 9 1 8 8 6 6 0 0 5 5 9 9 7 7 3 3\n",
      " 4 4 2 2 1 9 9 7 7 0 0 2 2 8 8 5 5 6 6 4 4 3 3 1 4 4 2 2 8 8 0 0 7 7 5 5 9\n",
      " 9 6 6 3 3 1 5 5 3 3 9 9 8 8 7 7 6 6 0 0 2 2 4 4 1 0 0 6 6 9 9 7 7 3 3 8 8\n",
      " 2 2 4 4 5 5 1 3 3 7 7 6 6 8 8 0 0 2 2 9 9 4 4 5 5 1 7 7 3 3 0 0 6 6 4 4 5\n",
      " 5 9 9 2 2 8 8 1 4 4 9 9 5 5 8 8 7 7 2 2 0 0 6 6 3 3 1 5 5 6 6 8 8 7 7 4 4\n",
      " 0 0 2 2 3 3 9 9 1 8 8 7 7 5 5 6 6 2 2 9 9 3 3 0 0 4 4 1 3 3 4 4 7 7 2 2 6\n",
      " 6 8 8 9 9 0 0 5 5 1 8 8 4 4 7 7 0 0 2 2 6 6 9 9 5 5 3 3 1 4 4 5 5 6 6 8 8\n",
      " 3 3 9 9 7 7 2 2 0 0 1 9 9 7 7 3 3 0 0 4 4 8 8 5 5 2 2 6 6 1 5 5 6 6 8 8 0\n",
      " 0 4 4 7 7 3 3 2 2 9 9 1 3 3 8 8 4 4 0 0 5 5 6 6 2 2 9 9 7 7 1 2 2 8 8 6 6\n",
      " 9 9 7 7 3 3 0 0 4 4 5 5 1 9 9 2 2 8 8 0 0 3 3 4 4 6 6 7 7 5 5 1 2 2 0 0 5\n",
      " 5 4 4 9 9 3 3 6 6 8 8 7 7 1 6 6 2 2 0 0 8 8 4 4 3 3 9 9 5 5 7 7 1 6 6 4 4\n",
      " 2 2 9 9 5 5 7 7 0 0 8 8 3 3 1 8 8 9 9 7 7 5 5 4 4 2 2 6 6 0 0 3 3 1 3 3 0\n",
      " 0 5 5 9 9 6 6 2 2 8 8 7 7 4 4 1 5 5 2 2 9 9 6 6 8 8 7 7 3 3 4 4 0 0 1 5 5\n",
      " 0 0 4 4 2 2 9 9 6 6 8 8 7 7 3 3 1 8 8 0 0 3 3 2 2 7 7 5 5 6 6 9 9 4 4 1 8\n",
      " 8 3 3 9 9 5 5 4 4 6 6 0 0 7 7 2 2 1 7 7 9 9 6 6 2 2 5 5 4 4 3 3 0 0 8 8 1\n",
      " 5 5 4 4 3 3 9 9 0 0 2 2 7 7 8 8 6 6]\n"
     ]
    }
   ],
   "source": [
    "y = list(target_total)\n",
    "print(y)\n",
    "\n",
    "# transform the target_set unique strings to integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "runs_group = np.repeat(np.arange(9), 76)\n",
    "print(runs_group)\n",
    "print(np.unique(runs_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(684,)\n"
     ]
    }
   ],
   "source": [
    "print(runs_group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decoder(estimator, mask, cv, X, y, groups, smoothing, scoring, mask_strategy, results_dir, part_id, ses_id):\n",
    "    \"\"\"\n",
    "    Function to fit the Nilearn Decoder, save the model, and organize results into structured directories.\n",
    "    \"\"\"\n",
    "    decoder_name = f\"{estimator}_{mask_strategy}_fwhm{smoothing}_{scoring}\"\n",
    "    scoring_dir = os.path.join(results_dir, 'nilearn', part_id, ses_id, scoring)\n",
    "    decoder_path = os.path.join(scoring_dir, f\"{decoder_name}.pkl\")\n",
    "    \n",
    "    if not os.path.exists(scoring_dir):\n",
    "        os.makedirs(scoring_dir)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        \n",
    "        # Initialize and fit decoder\n",
    "        decoder = Decoder(\n",
    "            estimator=estimator,\n",
    "            mask=mask,\n",
    "            cv=cv,\n",
    "            smoothing_fwhm=smoothing,\n",
    "            mask_strategy=mask_strategy,\n",
    "            scoring=scoring,\n",
    "            standardize=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        decoder.fit(X, y, groups=groups)\n",
    "        \n",
    "        # Save decoder\n",
    "        with open(decoder_path, 'wb') as f:\n",
    "            pickle.dump(decoder, f)\n",
    "        print(f\"Decoder salvo em: {decoder_path}\")\n",
    "        \n",
    "        return {\n",
    "            \"Decoder\": decoder_name,\n",
    "            \"Smoothing\": smoothing,\n",
    "            \"Scoring Method\": scoring,\n",
    "            \"Mask Strategy\": mask_strategy,\n",
    "            \"Decoder Path\": decoder_path\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro com {decoder_name}: {e}\")\n",
    "        return {\n",
    "            \"Decoder\": decoder_name,\n",
    "            \"Smoothing\": smoothing,\n",
    "            \"Scoring Method\": scoring,\n",
    "            \"Mask Strategy\": mask_strategy,\n",
    "            \"Error\": str(e),\n",
    "            \"Decoder Path\": decoder_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_decoders(base_dir, scoring_methods):\n",
    "    \"\"\"\n",
    "    Procura e carrega automaticamente todos os arquivos .pkl dentro das pastas de scoring (ex: 'roc_auc' ou 'accuracy').\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): Diretório base onde estão as pastas de scoring.\n",
    "        scoring_methods (list): Lista das pastas possíveis de scoring.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tuples contendo (decoder, decoder_path, scoring_method).\n",
    "    \"\"\"\n",
    "    decoders_list = []\n",
    "\n",
    "    for method in scoring_methods:\n",
    "        scoring_path = os.path.join(base_dir, method)\n",
    "\n",
    "        if os.path.exists(scoring_path):  # Verifica se a pasta existe\n",
    "            for file in os.listdir(scoring_path):  # Percorre os arquivos\n",
    "                if file.endswith(\".pkl\"):  # Procura arquivos .pkl\n",
    "                    decoder_path = os.path.join(scoring_path, file)\n",
    "                    try:\n",
    "                        with open(decoder_path, 'rb') as f:\n",
    "                            decoder = pickle.load(f)\n",
    "                        print(f\"Decoder carregado de: {decoder_path}\")\n",
    "                        decoders_list.append((decoder, decoder_path, method))  # Armazena o decoder, caminho e a pasta de origem\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao carregar decoder de {decoder_path}: {e}\")\n",
    "\n",
    "    if decoders_list:\n",
    "        return decoders_list  # Retorna todos os decoders encontrados\n",
    "    else:\n",
    "        print(\"Nenhum decoder encontrado!\")\n",
    "        return []  # Retorna lista vazia se nada for encontrado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(decoder, results_dir, part_id, ses_id):\n",
    "    \"\"\"Save CV scores and coefficient images.\"\"\"\n",
    "\n",
    "    decoder_name = os.path.splitext(os.path.basename(decoder[1]))[0] # Get decoder name from decoder[1] -> path splitext[0] = takes out the .pkl\n",
    "\n",
    "    # cv_scores_path = os.path.join(results_dir, 'nilearn', part_id, ses_id, 'cv_scores', decoder[2], decoder_name)\n",
    "    path = os.path.join(results_dir, 'nilearn', part_id, ses_id, decoder[2], decoder_name)\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # if not os.path.exists(coef_imgs_path):\n",
    "    #     os.makedirs(coef_imgs_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Save cross-validation scores\n",
    "\n",
    "    cv_scores = [decoder[0].cv_scores_[i] for i in range(len(decoder[0].cv_scores_))]\n",
    "\n",
    "    cv_scores_mean = np.mean(cv_scores, axis=1)\n",
    "\n",
    "    df = pd.DataFrame(cv_scores_mean, columns=['score'])\n",
    "    df['label'] = le.classes_ # Use class labels from cv_scores_ keys\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'target': le.classes_, 'cv_score': cv_scores_mean})\n",
    "\n",
    "    csv_path = os.path.join(path, f\"{decoder_name}_cv_scores.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    #print(f\"Resultados salvos em: {csv_path}\")\n",
    "    \n",
    "    coef_img = [decoder[0].coef_img_[i] for i in range(len(decoder[0].coef_img_))]\n",
    "\n",
    "    coef_final_path = os.path.join(path, f\"{decoder_name}_coef_img.pkl\")\n",
    "\n",
    "    \n",
    "    jl.dump(coef_img, coef_final_path)\n",
    "    \n",
    "       \n",
    "    # Save coefficient images\n",
    "    #coef_imgs = enumerate(decoder[0].coef_img_):\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_coefs(base_dir, scoring_methods):\n",
    "    \"\"\"\n",
    "    Recursively searches for .pkl files within scoring method directories and loads them using joblib.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): Base directory where the scoring method folders are located.\n",
    "        scoring_methods (list): List of scoring method folder names (e.g., 'roc_auc', 'accuracy').\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples containing (coef_img, coef_path, scoring_method).\n",
    "    \"\"\"\n",
    "    coefs_list = []\n",
    "\n",
    "    for method in scoring_methods:\n",
    "        scoring_path = os.path.join(base_dir, method)\n",
    "\n",
    "        if os.path.exists(scoring_path):  # Check if the scoring folder exists\n",
    "            for root, _, files in os.walk(scoring_path):  # Recursively walk through all subdirectories\n",
    "                for file in files:\n",
    "                    if file.endswith(\".pkl\"):  # Look for .pkl files\n",
    "                        coef_path = os.path.join(root, file)\n",
    "                        try:\n",
    "                            coef_img = jl.load(coef_path)  # Load using joblib\n",
    "                            print(f\"Loaded coefficient from: {coef_path}\")\n",
    "                            coefs_list.append((coef_img, coef_path, method))  # Store coef_img, path, and scoring method\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error loading coefficient from {coef_path}: {e}\")\n",
    "\n",
    "    if coefs_list:\n",
    "        return coefs_list  # Return all found coefficients\n",
    "    else:\n",
    "        print(\"No coefficient files found!\")\n",
    "        return []  # Return an empty list if nothing is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\joblib\\memory.py:353: FutureWarning: The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.\n",
      "  return self.func(*args, **kwargs)\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sebas\\miniconda3\\envs\\nilearntest\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir diretórios e parâmetros\n",
    "decoders_dir = '../decoders_dir'\n",
    "part_id = 'subjects_2-10'\n",
    "ses_id = 'ses-01'\n",
    "estimators = ['svc_l2']\n",
    "scoring_metrics = ['roc_auc']\n",
    "smoothing_values = [4]\n",
    "mask_strategies = ['whole-brain-template']\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for estimator in estimators:\n",
    "    for scoring_method in scoring_metrics:\n",
    "        for smoothing in smoothing_values:\n",
    "            for mask_strategy in mask_strategies:\n",
    "                result = run_decoder(\n",
    "                    estimator=estimator,\n",
    "                    mask=mask_img,\n",
    "                    cv=logo,\n",
    "                    X=X_total,\n",
    "                    y=y,\n",
    "                    part_id=part_id,\n",
    "                    ses_id=ses_id,\n",
    "                    groups=runs_group,\n",
    "                    smoothing=smoothing,\n",
    "                    scoring=scoring_method,\n",
    "                    mask_strategy=mask_strategy,\n",
    "                    results_dir=decoders_dir,\n",
    "                )\n",
    "                # all_results.append(result)\n",
    "\n",
    "# summary_df = pd.DataFrame(all_results)\n",
    "# summary_filepath = os.path.join(results_dir, 'decoder_results_summary.csv')\n",
    "# summary_df.to_csv(summary_filepath, index=False)\n",
    "# print(f\"Resumo salvo em: {summary_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_decoder_dir = r\"..\\decoders_dir\\nilearn\\sub_2-10\\ses-01\"\n",
    "\n",
    "# Lista das subpastas onde pode estar o decoder\n",
    "scoring_methods = [\"roc_auc\"]\n",
    "\n",
    "\n",
    "# Chama a função para encontrar todos os decoders\n",
    "decoders = find_all_decoders(base_decoder_dir, scoring_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if decoders:\n",
    "    results_dir = '../results_seb'\n",
    "    part_id = 'subjects_2-10'\n",
    "    ses_id = 'ses-01'\n",
    "\n",
    "    for decoder in decoders:\n",
    "\n",
    "        # Acessa o cv_scores_ corretamente\n",
    "        save_results(decoder,results_dir, part_id, ses_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_imgs = jl.load(r'..\\results_seb/nilearn/sub_2-10/ses-01/roc_auc/svc_l2_gm-template_fwhm4_roc_auc/svc_l2_gm-template_fwhm4_roc_auc_coef_img.pkl')\n",
    "print(coef_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_coef_dir= os.path.join(results_dir,'nilearn', part_id, ses_id)\n",
    "\n",
    "base_coef_dir = r\"..\\results_seb\\nilearn\\sub_2-10\\ses-01\"\n",
    "scoring_methods = [\"roc_auc\"]\n",
    "\n",
    "\n",
    "coefs = find_all_coefs(base_coef_dir, scoring_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(np.unique(y))):\n",
    "\n",
    "    # get the indices of the target_set\n",
    "    idx = np.where(y == i)\n",
    "\n",
    "    subfolder_name = os.path.basename(os.path.dirname(coefs[3][1]))\n",
    "    \n",
    "\n",
    "\n",
    "    # plot the cv_scores_mean_i\n",
    "    plt = plotting.plot_stat_map(\n",
    "        coef_imgs[i],\n",
    "        title=f'{le.inverse_transform([i])[0]}_{subfolder_name}',\n",
    "        dim=-1,\n",
    "        threshold='auto',\n",
    "        cut_coords=(0, 0, 0),\n",
    "        draw_cross=False,\n",
    "        \n",
    "    \n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import mean_img\n",
    "\n",
    "\n",
    "# compute sum of all images in list\n",
    "\n",
    "# for each image in the list extract the data and sum them\n",
    "imgs = list(coefs[3][0])\n",
    "print(imgs)\n",
    "\n",
    "\n",
    "# create list img_data\n",
    "img_data = []\n",
    "\n",
    "i = 0\n",
    "for img in imgs:\n",
    "    # compute the absolute value of the image data\n",
    "    img_data.append(np.abs(img.get_fdata()))\n",
    "    print(img_data[i].shape)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.array(img_data)\n",
    "mean_img_coef = np.sum(img_data, axis=0)\n",
    "mean_img_coef = nib.Nifti1Image(mean_img_coef, mask_img.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cv_scores_mean_i\n",
    "plotting.view_img(\n",
    "    mean_img_coef,\n",
    "    title=f'{subfolder_name}',\n",
    "    threshold=\"95%\",\n",
    "    cut_coords=(0, 0, 0),\n",
    "    draw_cross=True,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification using scikit routines\n",
    "### Preparing the fmri Data to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker(\n",
    "    mask_img=mask_img,\n",
    "    standardize=\"zscore_sample\",\n",
    "    runs= runs_group,\n",
    "    smoothing_fwhm = 4,\n",
    "    memory=\"nilearn_cache\"\n",
    "    )\n",
    "X_masked = masker.fit_transform(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=52000)\n",
    "#using anova as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_ovo = OneVsOneClassifier(\n",
    "    Pipeline(\n",
    "        [\n",
    "            (\"anova\", selector),\n",
    "            (\"svc\", SVC(kernel=\"linear\")),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average, multi_class):\n",
    "\n",
    "  #creating a set of all the unique classes using the actual class list\n",
    "  unique_class = set(actual_class)\n",
    "  roc_auc_dict = {}\n",
    "  for per_class in unique_class:\n",
    "    #creating a list of all the classes except the current class \n",
    "    other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "    #marking the current class as 1 and all other classes as 0\n",
    "    new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "    new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "    #using the sklearn metrics method to calculate the roc_auc_score\n",
    "    roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average, multi_class = multi_class)\n",
    "    roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "  return roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = len(np.unique(runs_group))\n",
    "\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = {}\n",
    "lr_roc_auc_multiclass  = {}\n",
    "roc_vals_mc = {}\n",
    "cm = {}\n",
    "\n",
    "f=0\n",
    "for train_index, test_index in logo.split(X_masked, y, groups=runs_group):\n",
    "    \n",
    "    \n",
    "    X_train, X_test = X_masked[train_index], X_masked[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    svc_ovo.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svc_ovo.predict(X_test)\n",
    "    \n",
    "\n",
    "    # compute the confusion matrix\n",
    "    cm[f] = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # We will store the results in a dictionary for easy access later\n",
    "    per_class_accuracies = {}\n",
    "\n",
    "     # Calculate the accuracy for each one of our classes\n",
    "    for idx, cls in enumerate(set(y_test)):\n",
    "        # True negatives are all the samples that are not our current GT class (not the current row) and were not predicted as the current class (not the current column)\n",
    "        true_negatives = np.sum(np.delete(np.delete(cm[f], idx, axis=0), idx, axis=1))\n",
    "        \n",
    "        # True positives are all the samples of our current GT class that were predicted as such\n",
    "        true_positives = cm[f][idx, idx]\n",
    "        \n",
    "        # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "        per_class_accuracies[cls] = (true_positives + true_negatives) / np.sum(cm[f])\n",
    "\n",
    "    accuracy[f] = per_class_accuracies\n",
    "\n",
    "    roc_vals = roc_auc_score_multiclass(y_test, y_pred, average = 'micro', multi_class = 'ovo')\n",
    "\n",
    "\n",
    "    lr_roc_auc_multiclass[f] = list(roc_vals.values())\n",
    "\n",
    "\n",
    "    # roc_vals_mc[f] = roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "    f += 1\n",
    "    \n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'ROC AUC: {lr_roc_auc_multiclass}')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_accuracy = [list(accuracy[i].values()) for i in range(len(accuracy))]\n",
    "\n",
    "\n",
    "print(cv_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_roc_auc = np.mean(list(lr_roc_auc_multiclass.values()), axis=0)\n",
    "\n",
    "print(f'Mean ROC AUC: {mean_roc_auc}')\n",
    "\n",
    "\n",
    "\n",
    "# compute mean of the accuracy\n",
    "mean_accuracy = np.mean(cv_accuracy, axis=0)\n",
    "\n",
    "print(f'Mean accuracy: {mean_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# plot confusion matrix totals\n",
    "cm_total = np.zeros(cm[0].shape)\n",
    "\n",
    "for i in range(len(cm)):\n",
    "    cm_total += cm[i]\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(cm_total, annot= True, fmt='g', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_, )\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilearntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
